{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | |\n",
    "|-|-|\n",
    "| ![gym](images/gym.png) | ![img](images/pytorch.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание\n",
    "\n",
    "Является взаимодополняющим с заданием по контекстным бандитам, в сумме достаточно набрать 10 баллов.\n",
    "\n",
    "1. [5 баллов] Для произвольно выбранной игры из набора Atari реализовать нейросетевого агента для среды из регистров памяти.\n",
    "\n",
    "2. [5 баллов] Реализовать агента для среды со снимками экрана и сравнить с первым агентом.\n",
    "\n",
    "Приведите логи изменения продолжительности игры или количества набранных очков.\n",
    "\n",
    "Приложите ссылку на запись с моментами из игры обученного агента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The typical imports\n",
    "# import gym\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# \n",
    "\n",
    "# # Imports specifically so we can render outputs in Jupyter.\n",
    "# from matplotlib import animation\n",
    "# from IPython.display import display\n",
    "\n",
    "\n",
    "# def display_frames_as_gif(frames):\n",
    "#     \"\"\"\n",
    "#     Displays a list of frames as a gif, with controls\n",
    "#     \"\"\"\n",
    "#     #plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72)\n",
    "#     patch = plt.imshow(frames[0])\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     def animate(i):\n",
    "#         patch.set_data(frames[i])\n",
    "\n",
    "#     anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "#     display(anim, default_mode='loop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом занятии будем использовать библиотеку [openai](https://openai.com/systems/) `gym`, `pytorch` также будет использоваться для обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"requirements.txt\":\n",
    "\n",
    "```\n",
    "atari_py==0.2.6\n",
    "gym==0.15.4\n",
    "pyglet==1.3.2\n",
    "torch==1.3.1\n",
    "torchvision==0.4.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Агент взаимодействует со средой через действия (**A**), изменяя свое состояние (**S**) и получая вознаграждение (**R**).\n",
    "\n",
    "Итоговая цель -- максимизировать суммарное вознаграждение.\n",
    "\n",
    "![](images/recap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тележка\n",
    "\n",
    "![](images/cartpole.png)\n",
    "\n",
    "* **Цель** - как можно дольше удерживать стержень вертикально\n",
    "* **Состояние** - угол, угловая скорость, положение, горизонтальная скорость\n",
    "* **Действие** - горизонтальная сила, применяемая к тележке\n",
    "* **Вознаграждение** - 1 за каждый момент времени с околовертикальным стержнем (например, 85-95 градусов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atari\n",
    "\n",
    "![](images/atari.png)\n",
    "\n",
    "* **Цель** - побить рекорд по очкам\n",
    "* **Состояние** - экран игры (изображение)\n",
    "* **Действие** - различные клавиши\n",
    "* **Вознаграждение** - определяется игрой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doom\n",
    "\n",
    "![](images/doom.png)\n",
    "\n",
    "* **Цель** - уничтожить всех противников\n",
    "* **Состояние** - экран игры (изображение)\n",
    "* **Действие** - различные клавиши\n",
    "* **Вознаграждение** - +1 при убийстве противника, -N при смерти героя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дисконтирование вознаграждений\n",
    "\n",
    "В задачах обучения с подкреплениям часто вводится дисконтирующий коэффицент $\\gamma$.\n",
    "\n",
    "Без него суммарное вознаграждение за все будущие состояние с момента $t$ может быть определено как\n",
    "\n",
    "![](images/nodiscount.png)\n",
    "\n",
    "С ним же мы отдаем предпочтения больше текущим вознаграждениям, чем будущим, т.к. среда может быть изменчива:\n",
    "\n",
    "![](images/discount.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ценности\n",
    "\n",
    "Хочется для каждого состояния знать, насколько оно \"хорошее\" (valuable). Тогда мы бы знали, чего ожидать от перехода в данное состояние.\n",
    "\n",
    "Для этого и существуют функции ценности -- они вычисляют средний дисконтированный выигрыш при следовании некоторой стратегии $\\pi$.\n",
    "\n",
    "![](images/vpolicy.png)\n",
    "\n",
    "Существует также и функция, определяющая оптимальную оценку состояния как максимум оценок среди всех стратегий.\n",
    "\n",
    "![](images/voptimal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-функция\n",
    "\n",
    "Даже при наличии оптимальных оценок состояний, мы все еще не можем их произвольно устанавливать, а только выбирать действие `a`.\n",
    "\n",
    "Для эффективного выбора действия при некотором состояния есть еще Q-функция (оценивающая Quality$\\approx$эффективность такого действия).\n",
    "\n",
    "Более формально -- $Q^\\pi(s, a)$ выражает ожидаемое вознаграждение при выполнении действия `a` и дальнейшем следовании стратегии $\\pi$.\n",
    "\n",
    "Также как и с оценкой состоянии существует некоторая оптимальная $Q^*(s, a)$.\n",
    "\n",
    "Между двумя оптимальными функциями можно установить тождество:\n",
    "\n",
    "![](images/VQ.png)\n",
    "\n",
    "А оптимальная стратегия в свою очередь выражается через оптимальную Q-функцию:\n",
    "\n",
    "![](images/pioptimal.png)\n",
    "\n",
    "**Задача** поиска оптимальной стратегии для агента в итоге **сводится к определению $V^*$ и $Q^*$**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning\n",
    "\n",
    "Q(s, a) можно определить рекурсивно через уравнение Беллмана как\n",
    "\n",
    "![](images/bellman.png)\n",
    "\n",
    "Идея Q-обучения состоит в том, чтобы исходя из уравнения Беллмана оценивать Q итеративно:\n",
    "\n",
    "![](images/qiter.png)\n",
    "\n",
    "Изначально это ничего не дает, т.к. базовые аппроксимации будут случайными. Но чем больше узнает агент, тем ближе мы к $Q^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Самодельная\" среда\n",
    "\n",
    "![](images/zombie.png)\n",
    "\n",
    "Хотим съесть мороженое, и не натыкаться на зомби, действия -- выбор одной из 4 сторон для перемещения.\n",
    "\n",
    "Начальное состояние среды:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i *\n",
      "z c\n"
     ]
    }
   ],
   "source": [
    "ZOMBIE = \"z\"\n",
    "CAR = \"c\"\n",
    "ICE_CREAM = \"i\"\n",
    "EMPTY = \"*\"\n",
    "\n",
    "grid = [\n",
    "    [ICE_CREAM, EMPTY],\n",
    "    [ZOMBIE, CAR]\n",
    "]\n",
    "\n",
    "for row in grid:\n",
    "    print(' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс состояний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, grid, car_pos):\n",
    "        self.grid = grid\n",
    "        self.car_pos = car_pos\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, State) and self.grid == other.grid and self.car_pos == other.car_pos\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(str(self.grid) + str(self.car_pos))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"State(grid={self.grid}, car_pos={self.car_pos})\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Действия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "UP = 0\n",
    "DOWN = 1\n",
    "LEFT = 2\n",
    "RIGHT = 3\n",
    "\n",
    "ACTIONS = [UP, DOWN, LEFT, RIGHT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И опять же начальное состояние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State(grid=[['i', '*'], ['z', 'c']], car_pos=[1, 1])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_state = State(grid=grid, car_pos=[1, 1])\n",
    "start_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция взаимодействия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def act(state, action):\n",
    "    def new_car_pos(state, action):\n",
    "        p = deepcopy(state.car_pos)\n",
    "        if action == UP:\n",
    "            p[0] = max(0, p[0] - 1)\n",
    "        elif action == DOWN:\n",
    "            p[0] = min(len(state.grid) - 1, p[0] + 1)\n",
    "        elif action == LEFT:\n",
    "            p[1] = max(0, p[1] - 1)\n",
    "        elif action == RIGHT:\n",
    "            p[1] = min(len(state.grid[0]) - 1, p[1] + 1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown action {action}\")\n",
    "        return p\n",
    "\n",
    "    p = new_car_pos(state, action)\n",
    "    grid_item = state.grid[p[0]][p[1]]\n",
    "    \n",
    "    new_grid = deepcopy(state.grid)\n",
    "    \n",
    "    if grid_item == ZOMBIE:\n",
    "        reward = -100\n",
    "        is_done = True\n",
    "        new_grid[p[0]][p[1]] += CAR\n",
    "    elif grid_item == ICE_CREAM:\n",
    "        reward = 1000\n",
    "        is_done = True\n",
    "        new_grid[p[0]][p[1]] += CAR\n",
    "    elif grid_item == EMPTY:\n",
    "        reward = -1\n",
    "        is_done = False\n",
    "        old = state.car_pos\n",
    "        new_grid[old[0]][old[1]] = EMPTY\n",
    "        new_grid[p[0]][p[1]] = CAR\n",
    "    elif grid_item == CAR:\n",
    "        reward = -1\n",
    "        is_done = False\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown grid item {grid_item}\")\n",
    "\n",
    "    return State(grid=new_grid, car_pos=p), reward, is_done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "N_STATES = 4\n",
    "N_EPISODES = 20\n",
    "\n",
    "MAX_EPISODE_STEPS = 100\n",
    "\n",
    "MIN_ALPHA = 0.02\n",
    "\n",
    "alphas = np.linspace(1.0, MIN_ALPHA, N_EPISODES)\n",
    "gamma = 1.0\n",
    "eps = 0.2\n",
    "\n",
    "q_table = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(state, action=None):\n",
    "    if state not in q_table:\n",
    "        q_table[state] = np.zeros(len(ACTIONS))\n",
    "\n",
    "    if action is None:\n",
    "        return q_table[state]\n",
    "    \n",
    "    return q_table[state][action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state):\n",
    "    if random.uniform(0, 1) < eps:\n",
    "        return random.choice(ACTIONS) \n",
    "    else:\n",
    "        return np.argmax(q(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: total reward -> 999\n",
      "Episode 2: total reward -> 996\n",
      "Episode 3: total reward -> 999\n",
      "Episode 4: total reward -> 999\n",
      "Episode 5: total reward -> 999\n",
      "Episode 6: total reward -> 999\n",
      "Episode 7: total reward -> 999\n",
      "Episode 8: total reward -> 999\n",
      "Episode 9: total reward -> 998\n",
      "Episode 10: total reward -> 999\n",
      "Episode 11: total reward -> 999\n",
      "Episode 12: total reward -> 999\n",
      "Episode 13: total reward -> 998\n",
      "Episode 14: total reward -> 998\n",
      "Episode 15: total reward -> 998\n",
      "Episode 16: total reward -> 999\n",
      "Episode 17: total reward -> 999\n",
      "Episode 18: total reward -> -100\n",
      "Episode 19: total reward -> 999\n",
      "Episode 20: total reward -> 998\n"
     ]
    }
   ],
   "source": [
    "for e in range(N_EPISODES):\n",
    "    state = start_state\n",
    "    total_reward = 0\n",
    "    alpha = alphas[e]\n",
    "\n",
    "    for _ in range(MAX_EPISODE_STEPS):\n",
    "        action = choose_action(state)\n",
    "        next_state, reward, done = act(state, action)\n",
    "        total_reward += reward\n",
    "\n",
    "        q(state)[action] = q(state, action) + \\\n",
    "                alpha * (reward + gamma *  np.max(q(next_state)) - q(state, action))\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "    print(f\"Episode {e + 1}: total reward -> {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{State(grid=[['i', '*'], ['z', 'c']], car_pos=[1, 1]): array([999.        , 784.16189446, -86.93665572, 982.66205106]),\n",
       " State(grid=[['i', 'c'], ['z', '*']], car_pos=[0, 1]): array([ 936.49025099,  989.99890396, 1000.        ,  967.10727091]),\n",
       " State(grid=[['ic', 'c'], ['z', '*']], car_pos=[0, 0]): array([0., 0., 0., 0.]),\n",
       " State(grid=[['i', '*'], ['zc', 'c']], car_pos=[1, 0]): array([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State(grid=[['i', '*'], ['z', 'c']], car_pos=[1, 1])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State(grid=[['i', 'c'], ['z', '*']], car_pos=[0, 1])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_1 = act(start_state, choose_action(start_state))[0]\n",
    "state_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State(grid=[['ic', 'c'], ['z', '*']], car_pos=[0, 0])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_2 = act(state_1, choose_action(state_1))[0]\n",
    "state_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openai Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "observation = env.reset()\n",
    "for t in range(500):\n",
    "    screen = env.render(mode='rgb_array')\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f07685d6320>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05596592, -0.16772283, -0.0115651 ,  0.19088335])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(name, n_episodes=10):\n",
    "    env = gym.make(name)\n",
    "    try:\n",
    "        for i_episode in range(n_episodes):\n",
    "            observation = env.reset()\n",
    "            for t in range(100):\n",
    "                env.render()\n",
    "                action = env.action_space.sample()\n",
    "                observation, reward, done, info = env.step(action)\n",
    "                if done:\n",
    "                    print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "                    break\n",
    "    finally:\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo('Pong-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(4,)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import spaces\n",
    "space = spaces.Discrete(8) # Set with 8 elements {0, 1, 2, ..., 7}\n",
    "x = space.sample()\n",
    "assert space.contains(x)\n",
    "assert space.n == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo('Breakout-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as T\n",
    "\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "use_cuda = False  # torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "BoolTensor = torch.cuda.BoolTensor if use_cuda else torch.BoolTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.head = nn.Linear(448, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "observation = env.reset()\n",
    "for t in range(500):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "env.reset()\n",
    "screen = env.render(mode='rgb_array')\n",
    "env.step(env.action_space.sample())\n",
    "env.close()\n",
    "plt.imshow(screen)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(40, interpolation=Image.CUBIC),\n",
    "    T.ToTensor()\n",
    "])\n",
    "# This is based on the code from gym.\n",
    "screen_width = 600\n",
    "\n",
    "\n",
    "def get_cart_location():\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    screen = screen[:, 160:320]\n",
    "    view_width = 320\n",
    "    cart_location = get_cart_location()\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescare, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).type(Tensor)\n",
    "\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "env.reset()\n",
    "env.step(env.action_space.sample())\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "policy_net = DQN()\n",
    "target_net = DQN()\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "if use_cuda:\n",
    "    policy_net.cuda()\n",
    "    target_net.cuda()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state.type(FloatTensor)).data.max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return LongTensor([[random.randrange(2)]])\n",
    "\n",
    "\n",
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation).\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = BoolTensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)))\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                       if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE).type(Tensor)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.FloatTensor(episode_durations)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "    #     display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action[0, 0].item())\n",
    "        reward = Tensor([reward])\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "    # Update the target network\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran = memory.sample(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f07460fd978>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tran.state.cpu().squeeze(0).permute(1, 2, 0).numpy() + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "831"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
